from ct.clients import openai_api_key
from langchain_openai import OpenAIEmbeddings
from ct.langchain.assistant import LangchainAssistant
from ct.langchain.vectorstore import LangchainVectorStore
from typing import AsyncGenerator
import ollama

class LangchainRAG:
    def __init__(self, index_path: str = None):
        self.embedder = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.vectorstore = LangchainVectorStore(self.embedder, index_path)
        self.model= "gemma3:4b"
        
        # Verifica que el retriever se haya creado
        if not hasattr(self.vectorstore, 'retriever'):
            raise ValueError("VectorStore no se inicializÃ³ correctamente. Â¿El Ã­ndice existe?")
            
        self.assistant = LangchainAssistant(self.vectorstore.retriever)

    def classify_query(self, query: str) -> str:
        return ollama.generate(
        model= self.model,
        system="""
        Clasifica la entrada del usuario como uno de los siguientes valores:

        - 'relevante' si el mensaje trata exclusivamente sobre productos de tecnologÃ­a o cÃ³mputo, como laptops, computadoras, servidores, impresoras, monitores, telÃ©fonos, cÃ¡maras, accesorios tecnolÃ³gicos (teclados, mouse, mochilas para laptop, audÃ­fonos), redes, software, licencias, dispositivos inteligentes, componentes electrÃ³nicos (RAM, SSD, tarjetas madre), o si pregunta por precios, cotizaciones, soporte tÃ©cnico o compra de productos tecnolÃ³gicos.

        - 'irrelevante' si la consulta NO estÃ¡ relacionada con productos tecnolÃ³gicos. Esto incluye mensajes sobre alimentos, ropa, perfumes, artÃ­culos de cuidado personal, muebles, mascotas, deportes, celebridades, electrodomÃ©sticos del hogar (lavadoras, refrigeradores, estufas), preguntas filosÃ³ficas, polÃ­tica, religiÃ³n, chistes, salud o cualquier otra conversaciÃ³n casual o fuera del giro comercial de tecnologÃ­a.

        - 'inapropiado' si el mensaje contiene lenguaje ofensivo, sexual, violento, amenazante o vulgar, o si solicita productos de carÃ¡cter sexual.

        Ejemplos irrelevantes: "Quiero una hamburguesa", "Tienen paÃ±ales para bebÃ©?", "QuÃ© opinas de Messi?", "Me siento triste", "DÃ³nde queda CancÃºn", "Quiero comprar una blusa".

        Solo responde con una palabra exacta: 'relevante', 'irrelevante' o 'inapropiado'. No des explicaciones ni repitas el mensaje del usuario.
        """
        ,
        prompt=query,
        options={'temperature' : 0, 'top_p': 0.1, 'num_predict': 10}
    ).response

    def polite_answer(self, query: str) -> str:
        """
        Devuelve una respuesta prediseÃ±ada cuando la consulta es irrelevante.
        No utiliza un modelo de lenguaje, lo cual es mÃ¡s rÃ¡pido y confiable.
        """
        return (
            "Gracias por tu mensaje. Nuestra empresa se especializa exclusivamente en productos de tecnologÃ­a y cÃ³mputo, "
            "como laptops, impresoras, accesorios, redes, software y partes electrÃ³nicas.\n\n"
            "Tu consulta no parece estar relacionada con este tipo de productos. "
            "Por favor, intenta con una nueva pregunta enfocada en productos tecnolÃ³gicos. "
            "Estaremos encantados de ayudarte. ðŸ˜Š"
        )

    def ban_answer(self, query: str) -> str:
        """
        Devuelve una respuesta prediseÃ±ada cuando la consulta es clasificada como inapropiada.
        No utiliza un modelo de lenguaje para garantizar rapidez y control de tono.
        """
        return (
            "Hemos detectado que tu mensaje contiene lenguaje o contenido inapropiado. "
            "Te pedimos mantener un lenguaje respetuoso y adecuado.\n\n"
            "Si continÃºas con este tipo de mensajes, podrÃ­amos restringir tu acceso al servicio. "
            "Por favor, formula tus preguntas de manera cordial para que podamos ayudarte con gusto."
        )

    async def run(self, query: str, session_id: str = None, listaPrecio : str = None) -> AsyncGenerator[str, None]:
        """Ejecuta una consulta RAG y muestra los chunks de respuesta en tiempo real."""
        if session_id is None:
            session_id = "default_session"

        label = self.classify_query(query).strip().lower()
        yield f"Etiqueta de la consulta: {label}\n"

        if label == "relevante":
            async for chunk in self.assistant.answer(session_id, query, listaPrecio):
                yield chunk
        elif label == "irrelevante":
            yield self.polite_answer(query)
        elif label == "inapropiado":
            yield self.ban_answer(query)


        